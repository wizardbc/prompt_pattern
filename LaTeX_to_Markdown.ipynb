{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Markdown with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import streamlit as st\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "client = OpenAI(api_key=st.secrets[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the $\\LaTeX$ File\n",
    "- A Prompt Pattern Catalog to Enhance Prompt Engineering\n",
    "- https://arxiv.org/abs/2302.11382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/2302.11382v1\", \"r\") as f:\n",
    "  doc = f.read()\n",
    "doc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(s):\n",
    "  s = s.split('}')[0][1:].replace('\\\\', '').strip()\n",
    "  return re.sub(r'\\s+', ' ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, ref = doc.split(\"\\\\begin{thebibliography}\")\n",
    "ref = \"\\\\begin{thebibliography}\" + ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [\n",
    "  (get_name(s), '}'.join(s.split('}')[1:]).strip())\n",
    "  for s in doc.split(\"\\\\section\")[1:]\n",
    "]\n",
    "pd.DataFrame(sections, columns=['section', 'latex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsections = [\n",
    "  (n1, \"\", s) if i==0 else (n1, get_name(s), '}'.join(s.split('}')[1:]).strip())\n",
    "  for n1, t in sections\n",
    "  for i, s in enumerate(t.split(\"\\\\subsection\"))\n",
    "]\n",
    "pd.DataFrame(subsections, columns=['section', 'subsection', 'latex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsubsections = [\n",
    "  (n1, n2, \"\", s) if i==0 else (n1, n2, get_name(s), '}'.join(s.split('}')[1:]).strip())\n",
    "  for n1, n2, t in subsections\n",
    "  for i, s in enumerate(t.split(\"\\\\subsubsection\"))\n",
    "]\n",
    "pd.DataFrame(subsubsections, columns=['section', 'subsection', 'subsubsection', 'latex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [\n",
    "  (n1, n2, n3, f\"\\\\section{{{n1}}}\\n\\\\subsection{{{n2}}}\\n\\\\subsubsection{{{n3}}}\\n\"+s)\n",
    "  for n1, n2, n3, s in subsubsections if len(s) > 100\n",
    "]\n",
    "chunks.append((\"Authors and Abstract\", '', '', doc.split(\"\\\\section\")[0]))\n",
    "chunks.append((\"Bibliography\", '', '', ref))\n",
    "\n",
    "df_chunks = pd.DataFrame(chunks, columns=['section', 'subsection', 'subsubsection', 'latex'])\n",
    "df_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_mkdn = df_chunks[['section','subsection','subsubsection']].drop_duplicates().to_markdown()\n",
    "print(toc_mkdn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\n",
    "  {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": \"You convert a part of LaTeX document to a markdown text. Do NOT print anything else. Ignore auxiliary latex tags, but keep the citation code for reference.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "]\n",
    "\n",
    "def mk_msg(text, role='user'):\n",
    "  return {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "      {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": f\"{text}\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "\n",
    "def latex_to_mkdn(latex_chunk):\n",
    "  history.append(mk_msg(latex_chunk))\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=history,\n",
    "    temperature=0.3,\n",
    "    max_tokens=4095,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "  history.append(response.choices[0].message)\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks['text'] = df_chunks.latex.progress_apply(latex_to_mkdn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks.to_csv(\"./data/2302.11382v1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
